{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img style=\"float: right;\" src=\"static/small.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Basic Scikit-Learn Exercises\n",
    "\n",
    "See also: [Scikit-Learn Quick Start](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "\n",
    "See also: [Scikit-Learn Tutorials](http://scikit-learn.org/stable/tutorial/index.html)\n",
    "\n",
    "See also: [Scikit-Learn User Guide](http://scikit-learn.org/stable/user_guide.html)\n",
    "\n",
    "See also: [Scikit-Learn API Reference](http://scikit-learn.org/stable/modules/classes.html)\n",
    "\n",
    "See also: [Scikit-Learn Support Vector Machines](http://scikit-learn.org/stable/modules/svm.html)\n",
    "\n",
    "See also: [Scikit-Learn Nearest Neighbors](http://scikit-learn.org/stable/modules/neighbors.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Import sklearn, import pandas as pd, and pd.read_csv the CFPB CSV file into dataframe 'df'.\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/cfpb_complaints_with_fictitious_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer Claim</th>\n",
       "      <th>Amount Received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>332.63</td>\n",
       "      <td>130.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>54.79</td>\n",
       "      <td>49.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>215.04</td>\n",
       "      <td>155.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>73.99</td>\n",
       "      <td>46.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Product  Consumer Claim  Amount Received\n",
       "0       Credit card          332.63           130.22\n",
       "1   Debt collection           54.79            49.14\n",
       "2       Credit card          215.04           155.28\n",
       "3  Credit reporting            3.31             4.59\n",
       "4   Debt collection           73.99            46.02"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Filter your df down to 'Product', 'Consumer Claim', 'Amount Received' using [[]] notation. Which is our target?\n",
    "\n",
    "df = df[['Product', 'Consumer Claim', 'Amount Received']]\n",
    "df.head(5) # Our target is \"Product\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100544\n",
      "25136\n"
     ]
    }
   ],
   "source": [
    "# 3. From sklearn.cross_validation import train_test_split. Make a train/test split 80/20 (we won't use it though).\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=.2)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Assign df[['Consumer Claim', 'Amount Received']] to 'X'\n",
    "\n",
    "X = df[['Consumer Claim', 'Amount Received']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. Convert to raw values df['Product'].values and assign to 'y'\n",
    "\n",
    "y = df['Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6. From sklearn.preprocessing import StandardScaler. From sklearn.pipeline import Pipeline.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7. From sklearn.neighbors import KNeighborsClassifier. Make a scalar/knn pipeline.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('classifier', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Fit your pipeline with your X and y.\n",
    "\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Money transfers', 'Consumer Loan', 'Other financial service'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Use your newly fitted pipeline to predict classifications for [[100, 80], [5000, 4000], [350, 900]] .\n",
    "\n",
    "pipe.predict([[100, 80], [5000, 4000], [350, 900]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89779942,  0.89747691,  0.89510373])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. From sklearn.cross_validation import cross_val_score. Run cross val score on your pipeline.\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(pipe, X, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89679334986607062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11. Get the mean of cross validation scores from your pipeline,\n",
    "\n",
    "score_mean = scores.mean()\n",
    "score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Debt collection' 'Consumer Loan' 'Debt collection']\n"
     ]
    }
   ],
   "source": [
    "# 12. Now repeat with Support Vector Machine Classifier (sklearn.svm.SVC) pipeline. Which yields better results?\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('classifier', SVC())])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "\n",
    "print(pipe.predict([[100, 80], [5000, 4000], [350, 900]]))\n",
    "\n",
    "scores = cross_val_score(pipe, X, y)\n",
    "print(scores)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Next: [Back To Beginning](01_introduction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
